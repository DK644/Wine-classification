{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Функции будут работать, только если в датасете нет пропущенных значений**"
      ],
      "metadata": {
        "id": "YKLIv5DT9Wrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для статистических тестов на проверку соответствия распределению"
      ],
      "metadata": {
        "id": "mwi_k4U84O3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYVabbzv4K9D"
      },
      "outputs": [],
      "source": [
        "def statistic_test(df, alpha, test_name):\n",
        "  \"\"\"Функция первым аргументом принимает исследуемый датафрейм, вторым - уровень значимости,\n",
        "  третьим - используемый статистический тест, сначала выделяются числовые столбцы, а затем в цикле проверяются критерием.\n",
        "  Функция возвращает вывод о справедливости нулевой гипотезы для каждого числового столбца\"\"\"\n",
        "  num_columns = []\n",
        "  for column_name in df.columns:\n",
        "        if (df[column_name].dtypes != object):\n",
        "            num_columns +=[column_name]\n",
        "  for column_name in num_columns:\n",
        "    stat, p = test_name(df[column_name])\n",
        "    if p > alpha:\n",
        "      print(f'Для столбца {column_name} справедлива нулевая гипотеза, p-value = {p}')\n",
        "    else:\n",
        "      print(f'Для столбца {column_name} нулевая гипотеза отвергается, p-value = {p}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "statistic_test.__doc__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "yPq9NiLF5fol",
        "outputId": "ca8ca47a-d14f-4293-9faa-081782d27a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Функция первым аргументом принимает исследуемый датафрейм, вторым - уровень значимости,\\n  третьим - используемый статистический тест, сначала выделяются числовые столбцы, а затем в цикле проверяются критерием.\\n  Функция возвращает вывод о справедливости нулевой гипотезы для каждого числового столбца'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для проверки стат значимости коэффициента корреляции"
      ],
      "metadata": {
        "id": "7qsZ14KA6L2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr_test(df, alpha, test_name):\n",
        "  \"\"\"Функция первым аргументом принимает исследуемый датафрейм, вторым - уровень значимости,\n",
        "  третьим - используемый статистический тест, сначала выделяются числовые столбцы, а затем в цикле проверяются критерием.\n",
        "  Функция возвращает вывод о справедливости нулевой гипотезы для каждой пары столбцов\"\"\"\n",
        "  num_columns = []\n",
        "  for column_name in df.columns:\n",
        "    if (df[column_name].dtypes != object):\n",
        "            num_columns +=[column_name]\n",
        "    for column_name_1 in num_columns:\n",
        "      for column_name_2 in num_columns:\n",
        "        stat, p = test_name(df[column_name_1], df[column_name_2])\n",
        "        if p > alpha:\n",
        "          print(f'столбцы {column_name_1} и {column_name_2} КОРРЕЛИРОВАНЫ, p-value = {p}, r = {stat}')\n",
        "        else:\n",
        "          print(f'столбцы {column_name_1} и {column_name_2} НЕ КОРРЕЛИРОВАНЫ, p-value = {p}, r = {stat}')"
      ],
      "metadata": {
        "id": "kzBiC1U75lD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция-пайплайн для числовых и категориальных значений"
      ],
      "metadata": {
        "id": "kFBS_cMC9-Yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Недоработана для категориальных признаков"
      ],
      "metadata": {
        "id": "mncmHtU7VDJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "bVawX-9w-nSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def use_pipeline(df, model, metric, imput_scaler_num = None, imput_scaler_cat = None, num_scaler = None, cat_scaler = None):\n",
        "  \"\"\"Функция отделяет введённую целевую переменную, а предикторы предобрабатываются и поступают в модель для её обучения\"\"\"\n",
        "  Y = df[input(\"Введите целевую переменную: \").split()]\n",
        "  X = df.drop(Y.columns, axis= 1)\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=44)\n",
        "\n",
        "  # Числовая часть пайплайна\n",
        "  pipe_num = Pipeline([('imputer', imput_scaler_num()), ('scaler', num_scaler())])\n",
        "  # Категориальная часть пайплайна\n",
        "  pipe_cat = Pipeline([('imputer', imput_scaler_cat()), ('scaler', cat_scaler())])\n",
        "\n",
        "  # Задаём комбинированный пайплайн\n",
        "  col_transformer = ColumnTransformer([\n",
        "    ('num_preproc', pipe_num, [i for i in X.columns if X[i].dtype!='object']),\n",
        "    ('cat_preproc', pipe_cat, [i for i in X.columns if X[i].dtype=='object'])\n",
        "    ])\n",
        "\n",
        "  # Определяем итоговый пайплайн с учётом модели\n",
        "  final_pipe = Pipeline([('preproc', col_transformer), ('model', model)])\n",
        "  final_pipe.fit(X_train, Y_train)\n",
        "  predict_values = final_pipe.predict(X_test)\n",
        "  res = metric(Y_test, predict_values, average='macro')\n",
        "  return res"
      ],
      "metadata": {
        "id": "a6A1mUWE-dUy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}